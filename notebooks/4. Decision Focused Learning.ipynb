{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Notebook setup\n",
    "# ============================================================\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Control figure size\n",
    "interactive_figures = True\n",
    "if interactive_figures:\n",
    "    # Normal behavior\n",
    "    %matplotlib widget\n",
    "    figsize=(9, 3)\n",
    "else:\n",
    "    # PDF export behavior\n",
    "    figsize=(14, 5)\n",
    "\n",
    "data_folder = '/app/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Decision-Focused Learning\n",
    "\n",
    "A Few Representative Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Predict, then Optimize\n",
    "\n",
    "**Industrial optimization problems typically rely on _estimated parameters_**\n",
    "\n",
    "E.g. travel times, demands, item weights/costs...\n",
    "\n",
    "<center><img src=\"assets/traffic.jpg\" width=\"70%\"/></center>\n",
    "\n",
    "**However, sometimes we have access to _a bit more information_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Predict, then Optimize\n",
    "\n",
    "**Take _traffic-dependent travel times_ as an example**\n",
    "\n",
    "If we know the _time of the day_ we can probably estimate them better!\n",
    "\n",
    "<center><img src=\"assets/traffic.jpg\" width=\"70%\"/></center>\n",
    "\n",
    "**Let's see how these problems are typically addressed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Predict, then Optimize\n",
    "\n",
    "**First, we train an estimator for the problem parameters:**\n",
    "\n",
    "$$\n",
    "\\arg \\min \\left\\{L({\\bf y}, {\\bf \\hat{y}}) \\mid {\\bf y} = f({\\bf \\hat{x}}; \\theta) \\right\\}\n",
    "$$\n",
    "* $L$ is the loss function\n",
    "* $f$ is the ML model with parameter \n",
    "* ${\\bf \\hat{x}}$, ${\\bf \\hat{y}}$ are the training set input/output\n",
    "\n",
    "**In our example:**\n",
    "\n",
    "* $x$ would be the time of the day\n",
    "* $y$ would be a vector of travel times\n",
    "* $L$ may be a classical MSE loss\n",
    "* $f$ may be a linear regressor or neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Predict, then Optimize\n",
    "\n",
    "**Then, we solve the optimization problem with the estimated parameters**\n",
    "\n",
    "$$\n",
    "\\arg \\min_z \\left\\{ c(z, y) \\mid z \\in F(y) \\right\\}\n",
    "$$\n",
    "* $z$ is the vector of variables of the optimization problem\n",
    "* $c$ is the cost function\n",
    "* $F$ is the feasible space\n",
    "* In general, both $c$ and $F$ may depend on the estimated parameters\n",
    "\n",
    "**In our example**\n",
    "\n",
    "* $z$ may represent routing decisions\n",
    "* $c$ may be the total travel time\n",
    "* $F$ may encode a deadline constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Predict, then Optimize\n",
    "\n",
    "**This approach is sometimes referred to as \"Predict, then Optimize\"**\n",
    "\n",
    "It is simple and it makes intuitively sense\n",
    "\n",
    "* If we manage to estimate well our parameters\n",
    "* ...The optimization model will be more accurate\n",
    "* ...And we will obtain better results\n",
    "\n",
    "**However, things are not really that simple!**\n",
    "\n",
    "* Our estimator will never be perfect, hence, we will _make mistakes_\n",
    "* If we are unlucky, these mistakes may lead to _completely wrong decisions_!\n",
    "\n",
    "**Say we want to move from location A to B**\n",
    "\n",
    "* There are two possible routes between them\n",
    "* ...And we need to pick one, based on (e.g.) time of the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Predict, then Optimize\n",
    "\n",
    "**Let us assume this is available data for training**\n",
    "\n",
    "<center><img src=\"assets/spo_example_1.png\" width=\"45%\"/></center>\n",
    "\n",
    "* The dashed line shows the input value that causes the optimal choice to switch\n",
    "* Image from [\"Smart Predict, then Optimize\"](https://pubsonline.informs.org/doi/pdf/10.1287/mnsc.2020.3922?casa_token=gJcIt01QHyAAAAAA:8WiWc-GVQzS8Jqvp1HO5NkLk-0EoDDcn12yQgtjv3M8--FMr5230ZpoDoOBWH0x4nhHX-YdGjg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Predict, then Optimize\n",
    "\n",
    "**If we train an optimal Linear Regression, we get these estimates**\n",
    "\n",
    "<center><img src=\"assets/spo_example_2.png\" width=\"45%\"/></center>\n",
    "\n",
    "* The estimator is quite accurate\n",
    "* ...But we get the switching point _wrong_!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Predict, then Optimize\n",
    "\n",
    "**By contrast, consider this second estimator**\n",
    "\n",
    "<center><img src=\"assets/spo_example_3.png\" width=\"45%\"/></center>\n",
    "\n",
    "* The accuracy is awful\n",
    "* ...But we get the switching point _right_!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Decision Focused Learning\n",
    "\n",
    "**The estimator and the optimizer _value mistakes differently_**\n",
    "\n",
    "* In the estimator we typically care for maximum likelihood\n",
    "* In the optimization problem, we care about _cost_\n",
    "\n",
    "> **What if we trained the estimator for _cost minimization_?**\n",
    "\n",
    "**This is the central idea in _decision-focused learning_**\n",
    "\n",
    "In principle, the training problem we need to solve is:\n",
    "$$\n",
    "\\arg \\min_{\\theta} \\left\\{ \\sum_{i=1}^m c(z_i, y_i) \\mid \\forall i=1..m : y_i = f(x_i; \\theta), z_i = \\arg\\min_{z \\in F(y_i)} c(z, y_i) \\right\\}\n",
    "$$\n",
    "\n",
    "* ...Which is unfortunately hard to tackle, since the $\\arg \\min$ is non-differentiable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sub-gradient to the Rescue\n",
    "\n",
    "**We could could _fix the estimator output_ $y_i$ in the optimization problem**\n",
    "\n",
    "* Formally, let $y_i^*$ be the output for example $i$ with the current parameters\n",
    "* The we consider the following simplified loss:\n",
    "$$\n",
    "\\tilde{L}(\\theta) = \\sum_{i=1}^m c(z_i^*, y_i) \\\\\n",
    "\\text{ with: } y_i = f(x_i; \\theta) \\text{ and: } z_i^* = \\arg\\min_{z \\in F(y_i^*)} c(z, y_i^*)\n",
    "$$\n",
    "\n",
    "Since all $z_i^*$ are now constant, we can obtain a _sub-gradient_:\n",
    "$$\n",
    "\\nabla_{\\theta} \\tilde{L}(\\theta)\n",
    "$$\n",
    "* In an implementation, we compute all (constant) $z_i^*$ in the forward pass...\n",
    "* ...The we differentiate as usual!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sub-gradient to the Rescue\n",
    "\n",
    "**If you just do this, things often work poorly**\n",
    "\n",
    "...Because the obtained sub-gradients are often not very good\n",
    "\n",
    "* This is an area of active research\n",
    "* With several _open problems_\n",
    "\n",
    "**Here are a couple of big issues that have been considered:**\n",
    "\n",
    "* How to take into account the constraints?\n",
    "  - When the constraints depend on the estimator output $y_i$\n",
    "  - ...They should be taken into account in the sub-gradient computation!\n",
    "* How to deal with linear cost functions?\n",
    "  - They seem easy to handle\n",
    "  - ...But in fact they are not!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dealing with Constraints\n",
    "\n",
    "**If our constraints are _differentiable_, we can _use a Lagrangian_**\n",
    "\n",
    "The main idea is to modify the loss to include the constraints as penalty terms:\n",
    "$$\n",
    "\\mathcal{L}(\\theta) = \\sum_{i=1}^m \\left( c(z_i^*, y_i) + \\lambda_i^T g(z_i^*, y_i) \\right)\n",
    "$$\n",
    "* Where $\\lambda_i$ is multiplier vector for example $i$\n",
    "* ...And all other symbols are the same as before\n",
    "\n",
    "The resulting sub-gradient include a _constraint-dependent contribution_\n",
    "\n",
    "**This leaves us with the problem of choosing the multipliers**\n",
    "\n",
    "* If the optimization problem is _convex_, then [this paper](https://arxiv.org/abs/1703.04529) gives a possible solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dealing with Constraints\n",
    "\n",
    "**For a broad class of (differentiable) optimization problems**\n",
    "\n",
    "* Given a local optimum $z_i^*$\n",
    "* There must exists a multiplier vector such that:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\nabla_{z_i} c(z_i^*, y_i^*) + \\sum_{j=1..n} \\nabla_{z_i} \\lambda_j g_j(z_i^*, y_i^*) = 0 \\\\\n",
    "g_j(z_i^*, y_i^*) \\leq 0 \\quad \\forall j = 1..n \\\\\n",
    "\\lambda_j \\geq 0 \\quad \\forall j = 1..n \\\\\n",
    "\\lambda_j g_j(z_i^*, y_i^*) = 0 \\quad \\forall j = 1..n\n",
    "\\end{align}$$\n",
    "\n",
    "* Where $n$ is the number of problem constraints\n",
    "* ...And we used the same notation as before, for consistency\n",
    "\n",
    "**These are known a [Karush-Kuhn Tucker (KKT) optimality conditions](https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dealing with Constraints\n",
    "\n",
    "**The KKT conditions may look scary**\n",
    "\n",
    "* ...But if we know $z_i^*$ already (e.g. because we have already solved the problem)\n",
    "* Then what we get is just _a system of linear equations in $\\lambda$_\n",
    "\n",
    "$$\\begin{align}\n",
    "\\nabla_{z_i} c(z_i^*, y_i^*) + \\sum_{j=1..n} \\nabla_{z_i} \\lambda_j g_j(z_i^*, y_i^*) = 0 \\\\\n",
    "g_j(z_i^*, y_i^*) \\leq 0 \\quad \\forall j = 1..n \\\\\n",
    "\\lambda_j \\geq 0 \\quad \\forall j = 1..n \\\\\n",
    "\\lambda_j g_j(z_i^*, y_i^*) = 0 \\quad \\forall j = 1..n\n",
    "\\end{align}$$\n",
    "\n",
    "* If we solve the system of equations\n",
    "* ...We can determine the optimal multipliers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dealing with Constraints\n",
    "\n",
    "**Overall, we perform one training step as follows**\n",
    "\n",
    "* We compute ${\\bf y^*} = f({\\bf x}; \\theta)$\n",
    "* We compute $z_i^* = \\arg\\min_{z \\in F(y_i^*)} c(z, y_i^*), \\ \\forall i=1..m$\n",
    "* We use the KKT conditions to determine $\\lambda_i^T$\n",
    "* Then we differentiate the Lagrangian loss:\n",
    "$$\n",
    "\\mathcal{L}(\\theta) = \\sum_{i=1}^m \\left( c(z_i^*, y_i) + \\lambda_i^T g(z_i^*, y_i) \\right)\n",
    "$$\n",
    "\n",
    "**The approach can work well, however**\n",
    "\n",
    "* It is restricted to convex, differentiable, optimization problems\n",
    "* It tends to suffer from stability issues\n",
    "* ...Typically this is mitigated via L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dealing with Linear Costs\n",
    "\n",
    "**Linear costs have been mostly studies in a specific context**\n",
    "\n",
    "...I.e. problems where the constraints _do not depend_ on the estimated parameters\n",
    "\n",
    "* In these cases, the basis for our sub-gradient is:\n",
    "$$\n",
    "\\tilde{L}(\\theta) = \\sum_{i=1}^m y_i^T z_i^* \\\\\n",
    "\\text{ with: } y_i = f(x_i; \\theta) \\text{ and: } z_i^* = \\arg\\min_{z \\in F} c(z, y_i^*)\n",
    "$$\n",
    "* Same as before, but with linear costs and a fixed feasible set $F$\n",
    "\n",
    "**This case if of interest for two reasons**\n",
    "\n",
    "* First, it occurs frequently in practice\n",
    "* Second, it works even with non-differentiable constraints (e.g. any MIP model)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dealing with Linear Costs\n",
    "\n",
    "**The problem with linear costs is that they can be made _trivially null_!**\n",
    "\n",
    "- If we have $y_i = 0$, the cost $y_i^T z_i^*$ becomes null by construction\n",
    "\n",
    "**The SotA to address this issue is to rely on _surrogate loss functions_**\n",
    "\n",
    "* For example the [SPO loss](https://pubsonline.informs.org/doi/pdf/10.1287/mnsc.2020.3922?casa_token=gJcIt01QHyAAAAAA:8WiWc-GVQzS8Jqvp1HO5NkLk-0EoDDcn12yQgtjv3M8--FMr5230ZpoDoOBWH0x4nhHX-YdGjg):\n",
    "$$\n",
    "\\tilde{L}_{\\mathit{SPO}}(\\theta) = \\sum_{i=1}^m (2y_i - \\hat{y}_i)^T (\\hat{z}_i^* - z_i^*)\n",
    "$$\n",
    "* Or one of the NCE losses from [this paper](https://people.cs.kuleuven.be/~tias.guns/files/ijcai21_nce_solpool.pdf):\n",
    "$$\n",
    "\\tilde{L}_{\\mathit{MAP}}(\\theta) = \\sum_{i=1}^m (y_i - \\hat{y}_i)^T (\\hat{z}_i^* - z_i^*)\n",
    "$$\n",
    "* Where $\\hat{z}_i^*$ is the optimum for the true costs $\\hat{y}_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dealing with Linear Costs\n",
    "\n",
    "**Both surrogate losses have a few common properties**\n",
    "\n",
    "Let's consider the NCE-MAP loss as an example:\n",
    "$$\n",
    "\\tilde{L}_{\\mathit{MAP}}(\\theta) = \\sum_{i=1}^m (y_i - \\hat{y}_i)^T (\\hat{z}_i^* - z_i^*)\n",
    "$$\n",
    "\n",
    "* It makes use of the estimated costs $y_i$\n",
    "  - Otherwise, there would be nothing to differentiate\n",
    "* It makes use of the true costs $\\hat{y}_i$\n",
    "  - We waste none of the available information\n",
    "* It is always non-negative (proof skipped)\n",
    "* It can be minimized by accurately predicting the costs\n",
    "* It can be minimized by guiding the optimizer toward the true solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Elephant in the Room\n",
    "\n",
    "**No matter which approach you pick, the is a big issue to deal with**\n",
    "\n",
    "I.e. computing a subgradient requires to solve an optimization problem\n",
    "\n",
    "* This may be even NP-hard\n",
    "* ...And you need to solve one problem per example (so $m$ per epoch)\n",
    "\n",
    "Meaning that we have considerable _scalability problems_\n",
    "\n",
    "**A few solutions have been proposed**\n",
    "\n",
    "* One approach is using [an LP relaxation](https://arxiv.org/pdf/2010.13943) (for MIPs)\n",
    "* Another simple approach consists in [caching previous solutions](https://people.cs.kuleuven.be/~tias.guns/files/ijcai21_nce_solpool.pdf)\n",
    "  - Formally, we replace: $z_i^* = \\arg\\min_{z \\in F} c(z, y_i^*)$\n",
    "  - With: $z_i^* = \\arg\\min_{z \\in S} c(z, y_i^*)$\n",
    "  - I.e. rather than solving a problem, we pick the best solution from a cache $S$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some Results\n",
    "\n",
    "**Some results for different methods on three problems**\n",
    "\n",
    "<center><img src=\"assets/p_and_o.png\" width=100%/></center>\n",
    "\n",
    "* Decision-focused learning improves considerable over the two-stage approach\n",
    "* All caching-based methods can be quite fast in practice!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "rise": {
   "center": false,
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
